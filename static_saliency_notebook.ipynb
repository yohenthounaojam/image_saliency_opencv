{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4509789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951db77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showed\n",
      "writing now\n",
      "wrote 1\n",
      "wrote 2\n",
      "waiting key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "# We first build the argument parser, then parse args...\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-i\", \"--image\", required=True, help=\"Path to input image\")\n",
    "# parser.add_argument(\"-o\", \"--save_to\", required=True, help=\"Path to save image excluding the saliencyType\")\n",
    "# parser.add_argument(\"-d\", \"--diff\", required=True, help=\"Differentiator\")\n",
    "# parser.add_argument(\"-a\", \"--here\", required=False, help=\"Ignores SaveTo and uses CWD to save output\")\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "# if args[\"here\"] == \"True\":\n",
    "#     args[\"save_to\"] = os.getcwd() + \"/output/\"\n",
    "\n",
    "\n",
    "#     python static_saliency.py --image images/example_image_original.png --save_to pp --diff pop --here yes\n",
    "\n",
    "# Load our input image\n",
    "img = cv2.imread(\"images/example_image_original.png\")\n",
    "di = \"na\"\n",
    "# Initialise OpenCV's static saliency SPECTRAL RESIDUAL DETECTOR and compute saliency map\n",
    "saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(img)\n",
    "saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
    "#cv2.imshow(\"Image\", img)\n",
    "#cv2.imshow(\"Output\", saliencyMap)\n",
    "cv2.imwrite(os.getcwd()+\"/output\" + \"/{}_lowfi_image_saliency.png\".format(di), saliencyMap)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Initialise the more fine-grained saliency detector and compute the saliencyMap\n",
    "saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(img)\n",
    "\n",
    "# If we want a *binary* map to use for contour processing,\n",
    "# computing convex hulls, extract bounding boxes, etc... we can \n",
    "# additionally threshold the saliency map.\n",
    "threshMap = cv2.threshold(saliencyMap.astype(\"uint8\"), 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Show Images\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Output\", saliencyMap)\n",
    "cv2.imshow(\"Thresholds\", threshMap)\n",
    "print(\"showed\")\n",
    "impath = os.getcwd() + \"/output\" + \"/{}_image_original_exp.png\".format(di)\n",
    "salpath = os.getcwd() + \"/output\" + \"/{}_image_saliency_exp.png\".format(di)\n",
    "threshpath = os.getcwd() + \"/output\" + \"/{}_image_thresh_exp.png\".format(di)\n",
    "print(\"writing now\")\n",
    "cv2.imwrite(impath, img)\n",
    "print(\"wrote 1\")\n",
    "cv2.imwrite(salpath, saliencyMap)\n",
    "print(\"wrote 2\")\n",
    "cv2.imwrite(threshpath, threshMap)\n",
    "print(\"waiting key\")\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07cc49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
